# Example batch job configurations

# Simple: 5 jobs with different learning rates
learning_rates: [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]
model: llama-7b
dataset: wikitext
epochs: 1
verbose: false

# Alternative: grid search over multiple parameters
# learning_rates: [0.0001, 0.0002]
# models: [llama-7b, llama-13b]
# epochs: [1, 3]
# verbose: false
